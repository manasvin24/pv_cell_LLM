# LLM Pipeline â€” Complete Architecture & Detailed Working

## 1. System Overview

This project implements a **zero-cloud, fully local LLM pipeline** for PV (photovoltaic) solar panel sizing recommendations. The pipeline ingests real-world data from 3 sources, engineers 75+ domain-specific features, augments them with curated domain knowledge via RAG, and feeds everything into a locally-hosted LLM (Llama 3.1 8B) to produce actionable PV installation recommendations for residential households in San Diego County.

**Key Statistics:**
- **30 San Diego locations** processed in a single batch
- **75+ features** computed per location
- **3 data sources** (electricity, weather, household) totalling ~45,000 data points per location
- **5-year historical data** window
- **~144 seconds** average processing time per location
- **60 output files** generated (2 per location)

---

## 2. High-Level Architecture Diagram

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    LLM WORKFLOW: PV PANEL SIZING ADVISOR                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                             â•‘
â•‘  â”‚ config.yaml  â”‚   User-facing YAML with all tunable parameters             â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                             â•‘
â•‘         â”‚                                                                    â•‘
â•‘         â–¼                                                                    â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â•‘
â•‘  â”‚  WorkflowConfig  â”‚   22 parameters: lat/lon, model, budget, etc.          â•‘
â•‘  â”‚  (config.py)     â”‚   Validates backend, RAG path, prompt                  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â•‘
â•‘         â”‚                                                                    â•‘
â•‘         â–¼                                                                    â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â•‘
â•‘  â”‚                    PIPELINE (pipeline.py)                     â”‚             â•‘
â•‘  â”‚                                                               â”‚             â•‘
â•‘  â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚             â•‘
â•‘  â”‚  â•‘  STEP 0: DATA EXTRACTION (data_extractor.py)          â•‘   â”‚             â•‘
â•‘  â”‚  â•‘                                                       â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ Open-Meteo   â”‚  â”‚ EIA Regional  â”‚  â”‚ Aggregate â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ Weather API  â”‚  â”‚ Load CSV      â”‚  â”‚ Hourlyâ†’   â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    â”‚         â”‚  â”‚    â”‚          â”‚  â”‚ Weekly    â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    â–¼         â”‚  â”‚    â–¼          â”‚  â”‚    â”‚      â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ weather.csv  â”‚  â”‚ household.csv â”‚  â”‚    â–¼      â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ (261 rows)   â”‚  â”‚ (44,306 rows) â”‚  â”‚ elec.csv  â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 10 columns   â”‚  â”‚ 2 columns     â”‚  â”‚ (267 rows)â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘   â”‚             â•‘
â•‘  â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚             â•‘
â•‘  â”‚         â”‚                    â”‚                    â”‚           â”‚             â•‘
â•‘  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚             â•‘
â•‘  â”‚                              â”‚                                â”‚             â•‘
â•‘  â”‚                              â–¼                                â”‚             â•‘
â•‘  â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚             â•‘
â•‘  â”‚  â•‘  STEP 1: FEATURE ENGINEERING (feature_engineering.py) â•‘   â”‚             â•‘
â•‘  â”‚  â•‘                                                       â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 7 Feature Categories, 60+ Functions:            â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 1. Electricity (15 features)                    â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    Load distribution, seasonality, trends       â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 2. Weather/Solar (12 features)                  â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    Irradiance, PSH, cloud cover, efficiency     â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 3. Household (7 features)                       â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    Per-occupant, per-sqm, costs                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 4. Cross-Dataset (10 features)                  â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    Self-sufficiency, payback, grid dependency    â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 5. Risk & Sensitivity (8 features)              â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    Price sensitivity, irradiance sensitivity     â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 6. EV & Budget (5 features)                     â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚    EV charging load, budget-constrained sizing   â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                                 â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ 7. Formatting â†’ LLM-ready text (~4,000 chars)   â”‚  â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘   â”‚             â•‘
â•‘  â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚             â•‘
â•‘  â”‚                                        â”‚                      â”‚             â•‘
â•‘  â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚             â•‘
â•‘  â”‚                              â”‚                                â”‚             â•‘
â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                                â”‚             â•‘
â•‘  â”‚  â”‚ knowledge.txt  â”‚          â”‚                                â”‚             â•‘
â•‘  â”‚  â”‚ (158 lines)    â”‚          â”‚                                â”‚             â•‘
â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚                                â”‚             â•‘
â•‘  â”‚         â”‚                    â”‚                                â”‚             â•‘
â•‘  â”‚         â–¼                    â”‚                                â”‚             â•‘
â•‘  â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—       â”‚                                â”‚             â•‘
â•‘  â”‚  â•‘ STEP 2: RAG      â•‘       â”‚                                â”‚             â•‘
â•‘  â”‚  â•‘ (retriever.py)   â•‘       â”‚                                â”‚             â•‘
â•‘  â”‚  â•‘                  â•‘       â”‚                                â”‚             â•‘
â•‘  â”‚  â•‘ TF-IDF Index     â•‘       â”‚                                â”‚             â•‘
â•‘  â”‚  â•‘ Cosine Sim       â•‘       â”‚                                â”‚             â•‘
â•‘  â”‚  â•‘ Top-5 Passages   â•‘       â”‚                                â”‚             â•‘
â•‘  â”‚  â•šâ•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•       â”‚                                â”‚             â•‘
â•‘  â”‚           â”‚                  â”‚                                â”‚             â•‘
â•‘  â”‚           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚             â•‘
â•‘  â”‚                  â”‚                                            â”‚             â•‘
â•‘  â”‚                  â–¼                                            â”‚             â•‘
â•‘  â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚             â•‘
â•‘  â”‚  â•‘  STEP 3: PROMPT BUILDER (prompt_builder.py)           â•‘   â”‚             â•‘
â•‘  â”‚  â•‘                                                       â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ ## DATA CONTEXT (Feature Summary, ~4K chars)  â”‚    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ ## KNOWLEDGE BASE (RAG Passages, ~2.5K chars) â”‚    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ ## QUESTION / INSTRUCTION (~1K chars)         â”‚    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚                                               â”‚    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ Total: ~8,000 characters                      â”‚    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚ Max cap: 32,000 characters                    â”‚    â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘   â”‚             â•‘
â•‘  â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚             â•‘
â•‘  â”‚                                â”‚                              â”‚             â•‘
â•‘  â”‚                                â–¼                              â”‚             â•‘
â•‘  â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚             â•‘
â•‘  â”‚  â•‘  STEP 4: LLM INFERENCE                                â•‘   â”‚             â•‘
â•‘  â”‚  â•‘                                                       â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚  Ollama Backend  â”‚ OR â”‚  vLLM Backend        â”‚      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚  llama3.1:8b     â”‚    â”‚  Meta-Llama-3-8B    â”‚      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚  REST /api/chat  â”‚    â”‚  OpenAI /v1/chat    â”‚      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚  Streaming NDJSONâ”‚    â”‚  Single response    â”‚      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â”‚  Port 11434      â”‚    â”‚  Port 8000          â”‚      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘   â”‚             â•‘
â•‘  â”‚  â•‘           â”‚                                            â•‘   â”‚             â•‘
â•‘  â”‚  â•‘           â–¼                                            â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  LLM Response (~3,000 chars)                           â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â€¢ PV panel recommendation                             â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â€¢ Financial analysis (ROI, payback)                   â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â€¢ Risk assessment                                     â•‘   â”‚             â•‘
â•‘  â”‚  â•‘  â€¢ Battery storage advice                              â•‘   â”‚             â•‘
â•‘  â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚             â•‘
â•‘  â”‚                                â”‚                              â”‚             â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â•‘
â•‘                                   â”‚                                            â•‘
â•‘                                   â–¼                                            â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â•‘
â•‘                        â”‚  OUTPUT FILES           â”‚                              â•‘
â•‘                        â”‚                        â”‚                              â•‘
â•‘                        â”‚  {location}_output.txt  â”‚  â† LLM recommendation      â•‘
â•‘                        â”‚  {location}_feature_    â”‚                              â•‘
â•‘                        â”‚    outputs.txt          â”‚  â† Feature summary          â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 3. Detailed Data Flow â€” Numeric Trace

This section traces **exact data sizes and transformations** through the pipeline for San Diego (32.7160, -117.1611):

### Stage 0 â†’ Stage 1: Raw Data

| Data Source | Rows | Columns | Granularity | Span |
|-------------|------|---------|-------------|------|
| `weather_data.csv` | 261 | 10 | Weekly | 5 years (2021â€“2026) |
| `household_data.csv` | 44,306 | 2 | Hourly | 5 years |
| `electricity_data.csv` | 267 | 5 | Weekly | 5 years |
| **Total raw data points** | | | | **~44,834** |

### Stage 1 â†’ Stage 2: Feature Engineering

| Category | # Features | Key Outputs |
|----------|-----------|-------------|
| Electricity Load | 15 | peak=7.79 kW, avg=2.25 kW, CV=0.104 |
| Weather/Solar | 12 | irradiance=219.82 W/mÂ², PSH=1.76 hrs |
| Household | 7 | annual=19,624 kWh, cost=$6,083/yr |
| Cross-Dataset | 10 | 128 panels for 100%, payback=15.7 yr |
| Risk/Sensitivity | 8 | ROI baseline=132.15%, risk=0.209 |
| EV & Budget | 5 | 31 panels within $15K budget |
| **Total** | **~75** | **Formatted: ~4,000 chars** |

### Stage 2: RAG Retrieval

| Metric | Value |
|--------|-------|
| Knowledge base size | 158 lines (~4 KB) |
| Chunks created | ~8â€“10 |
| Chunks retrieved | 5 |
| RAG context size | ~2,500 chars |

### Stage 3: Prompt Assembly

| Component | Characters | % of Total |
|-----------|-----------|------------|
| Feature summary | ~4,000 | 50% |
| RAG passages | ~2,500 | 30% |
| User prompt | ~1,000 | 12% |
| Headers/formatting | ~600 | 8% |
| **Total prompt** | **~8,100** | **100%** |

### Stage 4: LLM Output

| Metric | Value |
|--------|-------|
| Model | llama3.1:8b |
| Input tokens (est.) | ~2,000 tokens |
| Output tokens (max) | 4,096 tokens |
| Output characters | ~2,500â€“4,000 |
| Inference time | ~60â€“180 s |
| Sections generated | 6â€“8 (trends, sizing, costs, risks, battery, recommendation) |

---

## 4. Component Interaction Diagram

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Entry Points     â”‚
                          â”‚                   â”‚
                          â”‚  workflow.py       â”‚ â† Single location
                          â”‚  run_batch.py     â”‚ â† 30 locations
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   config.py        â”‚
                          â”‚   WorkflowConfig   â”‚â”€â”€â”€â”€ config.yaml
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   pipeline.py      â”‚
                          â”‚   Pipeline.run()   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                     â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ data_extractor.py  â”‚  â”‚ retriever.py   â”‚  â”‚ prompt_builder.py   â”‚
    â”‚                   â”‚  â”‚                â”‚  â”‚                     â”‚
    â”‚ regenerate_all()  â”‚  â”‚ RAGRetriever   â”‚  â”‚ PromptBuilder       â”‚
    â”‚   â”œâ”€ weather      â”‚  â”‚  .index()      â”‚  â”‚  .build()           â”‚
    â”‚   â”œâ”€ household    â”‚  â”‚  .retrieve()   â”‚  â”‚                     â”‚
    â”‚   â””â”€ electricity  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ feature_engineering.py  â”‚           â”‚ ollama_backend.py        â”‚
    â”‚                        â”‚           â”‚ vllm_backend.py          â”‚
    â”‚ extract_all_features() â”‚           â”‚                          â”‚
    â”‚ format_for_llm()       â”‚           â”‚ .generate()              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ weather_data.py    â”‚              â”‚ Ollama Server (port 11434)  â”‚
    â”‚ (Open-Meteo API)   â”‚              â”‚ or vLLM Server (port 8000)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                             â”‚
              â”‚                         â”‚ llama3.1:8b (4.7 GB)        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ household_extraction_      â”‚
    â”‚   per_house.py             â”‚
    â”‚ (EIA CSV â†’ per-household)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Module Inventory

| Module | Lines | Functions/Classes | Category |
|--------|-------|-------------------|----------|
| `config.py` | 116 | 1 class (`WorkflowConfig`) | Configuration |
| `config.yaml` | 85 | â€” | Configuration |
| `data_extractor.py` | 221 | 4 functions | Data Extraction |
| `weather_data.py` | 215 | 6 functions | Data Extraction |
| `household_extraction_per_house.py` | 748 | 5+ functions | Data Extraction |
| `feature_engineering.py` | 1,631 | 60+ functions | Feature Engineering |
| `retriever.py` | 168 | 1 class (`RAGRetriever`) | RAG |
| `prompt_builder.py` | 122 | 1 class (`PromptBuilder`) | Prompt Assembly |
| `ollama_backend.py` | 128 | 1 class (`OllamaBackend`) | LLM Inference |
| `vllm_backend.py` | 115 | 1 class (`VLLMBackend`) | LLM Inference |
| `pipeline.py` | 119 | 1 class (`Pipeline`) | Orchestration |
| `workflow.py` | 158 | 3 functions | Entry Point |
| `run_batch.py` | 169 | 5 functions | Batch Runner |
| `loader.py` | 132 | 1 class (`CSVLoader`) | Utility |
| **Total** | **~4,137** | | |

---

## 6. Technology Stack

| Layer | Technology | Version | Purpose |
|-------|-----------|---------|---------|
| **Language** | Python | 3.9+ | Core implementation |
| **LLM Runtime** | Ollama | Latest | Local LLM hosting |
| **Model** | Llama 3.1 8B | 8B params, 4.7 GB | Text generation |
| **Data Processing** | pandas | â‰¥2.0.0 | DataFrame operations |
| **Numerical** | numpy | â€” | Statistics, linear regression |
| **RAG** | scikit-learn | â‰¥1.3.0 | TF-IDF, cosine similarity |
| **HTTP** | requests | â‰¥2.31.0 | API calls (weather, LLM) |
| **Config** | PyYAML | â‰¥6.0 | YAML parsing |
| **Tables** | tabulate | â‰¥0.9.0 | Markdown formatting |
| **Progress** | tqdm | â€” | Batch progress bar |
| **Alt SDK** | openai | â‰¥1.0.0 | vLLM backend (optional) |

---

## 7. Data Sources â€” Detailed Schema

### 7.1 Weather Data (Open-Meteo API)

```
Source:    https://archive-api.open-meteo.com/v1/archive
Timeframe: 5 years ending 7 days ago
Scope:     Single point (lat, lon)
Columns:   10

 week_number | weekly_max_temp | weekly_min_temp | weekly_avg_temp |
             | weekly_max_irr  | weekly_min_irr  | weekly_avg_irr  |
             | weekly_max_cloud| weekly_min_cloud| weekly_avg_cloud|
```

### 7.2 Household Data (EIA Regional)

```
Source:    San_Diego_Load_EIA_Fixed.csv (1,040,149 meters)
Transform: Regional MW â†’ Per-household kW with 9 variability factors
Scope:     Location-specific via SHA256-seeded randomness
Columns:   2 (datetime_local, household_kw)
```

### 7.3 Electricity Data (Aggregated)

```
Source:    Derived from household_data.csv
Transform: Hourly â†’ Daily â†’ Weekly aggregation
Columns:   5 (week_number, max/min/avg load, start_date)
```

### 7.4 Knowledge Base (Curated Text)

```
Source:    Manually curated San Diego PV market data
Size:      158 lines, ~4 KB
Topics:    Installers, costs, tax credits, batteries, SDG&E policies
```

---

## 8. Execution Timeline (Single Location)

```
Time (s)  â”‚  Step
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 0.0      â”‚  Start: Load config, validate
 0.1      â”‚  Step 0: Fetch weather data (API call)
 5.0      â”‚  Step 0: Generate household data (EIA transform)
 8.0      â”‚  Step 0: Aggregate electricity data
 9.0      â”‚  Step 1: Load 3 CSVs into DataFrames
 9.5      â”‚  Step 1: Compute 75 features
10.5      â”‚  Step 1: Format summary, save to file
10.6      â”‚  Step 2: Index knowledge.txt (TF-IDF)
10.7      â”‚  Step 2: Retrieve top-5 passages
10.7      â”‚  Step 3: Resolve prompt variables
10.8      â”‚  Step 3: Assemble 3-section prompt
10.8      â”‚  Step 4: POST to Ollama /api/chat
10.9      â”‚  Step 4: Streaming response begins...
 ...      â”‚  Step 4: LLM generating tokens...
69.3      â”‚  Step 4: Streaming complete
69.3      â”‚  Save output.txt
69.3      â”‚  Done âœ“
```

---

## 9. LLM Prompt Engineering Strategy

The pipeline uses a **structured prompting strategy** with 3 information layers:

### Layer 1: System Prompt (Role Definition)

```
You are an expert power grid data analyst who can suggest the number
of PV cells that can be installed in any house based on weather,
electricity and household_data and is able to reason well on why the
recommendation is made. Be precise, cite numbers, and structure your
answer with clear sections and bullet points.
```

### Layer 2: Data Context (Feature-Engineered Summary)

The LLM receives pre-computed numerical features rather than raw data. This is critical because:
- Raw CSVs (44K+ rows) would exceed context windows
- Pre-computed features reduce hallucination risk
- Structured formatting guides the LLM's attention

### Layer 3: Knowledge Context (RAG Passages)

Real-world market data that supplements numerical analysis:
- Installation costs ($2.70â€“$3.30/W)
- Federal tax credits (30% ITC)
- SDG&E NEM 3.0 policies
- Battery storage costs ($8,000â€“$15,000)
- Local installer information

### Layer 4: Task Instruction (User Prompt)

A 7-point structured task with specific deliverables:
1. Review data summary and knowledge base
2. Identify trends and seasonal patterns
3. Factor in EV charging load
4. Assess budget constraints
5. Determine optimal panel count
6. Estimate savings and payback
7. Comment on risks and battery storage

---

## 10. Output Analysis

### Typical LLM Response Structure

```
## RECOMMENDATION FOR PV PANEL INSTALLATION

### KEY TRENDS AND SEASONAL PATTERNS
  â€¢ Annual consumption: 19,624 kWh
  â€¢ Stable demand, slight summer peak

### PV PANEL SIZING
  â€¢ 100% offset: 128 panels needed
  â€¢ Budget-constrained: 31 panels ($15,000)

### PAYBACK PERIOD AND ROI
  â€¢ Break-even: 10.03 years (budget-constrained)
  â€¢ ROI (25 yr): 132.15%
  â€¢ Annual savings: $1,480.42

### RISKS AND CAVEATS
  â€¢ Nighttime load ratio: 70.23%
  â€¢ Sunlight CV: 0.3141

### BATTERY STORAGE
  â€¢ Advisable for nighttime consumption offset
  â€¢ Cost: $8,000â€“$15,000

### FINAL RECOMMENDATION
  â€¢ Install 31 panels (within budget)
  â€¢ Expected production: 4,775 kWh/year
  â€¢ 5-7 year savings: $7,402â€“$10,363
```

---

## 11. Batch Processing â€” 30 Locations

### Processing Loop

```
FOR each of 30 locations:
    1. Deep copy base config
    2. Override: lat, lon, output paths
    3. Call Pipeline(cfg).run():
        a. Regenerate 3 CSVs for this lat/lon
        b. Compute 75 features
        c. Retrieve 5 RAG passages
        d. Assemble prompt
        e. Call LLM (Ollama)
    4. Save: {name}_output.txt, {name}_feature_outputs.txt
    5. Record timing
```

### Batch Performance

| Metric | Value |
|--------|-------|
| Total locations | 30 |
| Success rate | 100% (30/30) |
| Total runtime | ~72 minutes |
| Avg per location | ~144 seconds |
| Data extraction time | ~8 s/loc (5.5%) |
| Feature engineering | ~2 s/loc (1.4%) |
| RAG retrieval | <0.1 s/loc (0.1%) |
| Prompt assembly | <0.1 s/loc (0.1%) |
| **LLM inference** | **~134 s/loc (93%)** |
| Files generated | 60 (30 Ã— 2) |
| Total output size | ~210 KB |

**Key insight:** LLM inference dominates at 93% of total time. All data processing (extraction, features, RAG, prompt) takes only ~10 seconds combined.

---

## 12. Dependencies & Requirements

```
# requirements.txt
requests>=2.31.0         # HTTP: weather API, Ollama, vLLM
pyyaml>=6.0              # Config parsing
pandas>=2.0.0            # CSV loading, aggregation, statistics
tabulate>=0.9.0          # Markdown table formatting
scikit-learn>=1.3.0      # TF-IDF RAG indexing and retrieval
openai>=1.0.0            # vLLM backend (optional)
tqdm                     # Batch progress bar
```

**System requirements:**
- Python 3.9+
- Ollama installed and running (`brew install ollama`)
- `llama3.1:8b` model pulled (~4.7 GB)
- 8+ GB RAM (16 GB recommended)

---

## 13. File Structure

```
285_LLM_Workflow/
â”‚
â”œâ”€â”€ workflow.py                    â† CLI entry point (single)
â”œâ”€â”€ run_batch.py                   â† Batch runner (30 locations)
â”œâ”€â”€ config.yaml                    â† User configuration
â”œâ”€â”€ config.py                      â† WorkflowConfig dataclass
â”œâ”€â”€ pipeline.py                    â† 5-step orchestrator
â”œâ”€â”€ data_extractor.py              â† CSV regeneration from lat/lon
â”œâ”€â”€ feature_engineering.py         â† 75+ feature computation (1,631 lines)
â”œâ”€â”€ retriever.py                   â† TF-IDF RAG retriever
â”œâ”€â”€ prompt_builder.py              â† 3-section prompt assembler
â”œâ”€â”€ ollama_backend.py              â† Ollama REST API client
â”œâ”€â”€ vllm_backend.py                â† vLLM OpenAI-compatible client
â”œâ”€â”€ loader.py                      â† CSV loader utility
â”œâ”€â”€ requirements.txt               â† Python dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ electricity_data.csv       â† Weekly load (267 rows)
â”‚   â”œâ”€â”€ household_data.csv         â† Hourly usage (44,306 rows)
â”‚   â”œâ”€â”€ weather_data.csv           â† Weekly weather (261 rows)
â”‚   â”œâ”€â”€ knowledge.txt              â† RAG knowledge base (158 lines)
â”‚   â””â”€â”€ lats_longs_san_diego.csv   â† 30 location coordinates
â”‚
â”œâ”€â”€ data_extraction/
â”‚   â”œâ”€â”€ weather_data.py            â† Open-Meteo API client
â”‚   â””â”€â”€ Household_electricity_data/
â”‚       â”œâ”€â”€ household_extraction_per_house.py  â† EIA â†’ household
â”‚       â””â”€â”€ San_Diego_Load_EIA_Fixed.csv       â† Source EIA data
â”‚
â”œâ”€â”€ batch_outputs/                 â† 60 files (30 locations Ã— 2)
â”‚   â”œâ”€â”€ San_Diego_output.txt
â”‚   â”œâ”€â”€ San_Diego_feature_outputs.txt
â”‚   â”œâ”€â”€ Chula_Vista_output.txt
â”‚   â”œâ”€â”€ Chula_Vista_feature_outputs.txt
â”‚   â””â”€â”€ ... (56 more files)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ output.txt                 â† Single-run LLM output
â”‚   â””â”€â”€ feature_outputs.txt        â† Single-run features
â”‚
â””â”€â”€ readme/                        â† Pipeline documentation
    â”œâ”€â”€ 00_LLM_Pipeline_Overview.md  â† This file
    â”œâ”€â”€ 01_Configuration.md
    â”œâ”€â”€ 02_Data_Extraction.md
    â”œâ”€â”€ 03_Feature_Engineering.md
    â”œâ”€â”€ 04_RAG_Retriever.md
    â”œâ”€â”€ 05_Prompt_Builder.md
    â”œâ”€â”€ 06_LLM_Backends.md
    â”œâ”€â”€ 07_Pipeline_Orchestration.md
    â””â”€â”€ 08_Batch_Runner.md
```

---

## 14. Simplified Flow Diagram (for Image Generation)

Use this description to generate a visual pipeline diagram:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Weather  â”‚   â”‚Household â”‚   â”‚Knowledge â”‚
â”‚ API      â”‚   â”‚ EIA CSV  â”‚   â”‚   .txt   â”‚
â”‚(Open-    â”‚   â”‚(1M metersâ”‚   â”‚ (158 ln) â”‚
â”‚ Meteo)   â”‚   â”‚ regional)â”‚   â”‚          â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚
     â–¼              â–¼              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚weather   â”‚  â”‚household â”‚        â”‚
â”‚.csv      â”‚  â”‚.csv      â”‚        â”‚
â”‚261 rows  â”‚  â”‚44K rows  â”‚        â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚
     â”‚         â”Œâ”€â”€â”€â”˜              â”‚
     â”‚         â–¼                  â”‚
     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
     â”‚   â”‚electricityâ”‚            â”‚
     â”‚   â”‚.csv       â”‚            â”‚
     â”‚   â”‚267 rows   â”‚            â”‚
     â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â”‚
     â”‚        â”‚                   â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜                   â”‚
          â”‚                       â”‚
          â–¼                       â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
   â”‚  FEATURE      â”‚              â”‚
   â”‚  ENGINEERING  â”‚              â”‚
   â”‚  75 features  â”‚              â”‚
   â”‚  ~4,000 chars â”‚              â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
          â”‚                       â”‚
          â”‚                       â–¼
          â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚              â”‚  RAG         â”‚
          â”‚              â”‚  RETRIEVER   â”‚
          â”‚              â”‚  TF-IDF      â”‚
          â”‚              â”‚  5 passages  â”‚
          â”‚              â”‚  ~2,500 charsâ”‚
          â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PROMPT     â”‚
              â”‚   BUILDER    â”‚
              â”‚   3 sections â”‚
              â”‚   ~8K chars  â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   LLM        â”‚
              â”‚   Llama 3.1  â”‚
              â”‚   8B params  â”‚
              â”‚   Ollama     â”‚
              â”‚   ~144s      â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   OUTPUT     â”‚
              â”‚   PV Sizing  â”‚
              â”‚   Recommend. â”‚
              â”‚   ~3K chars  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Colour Coding Suggestion:**
- ğŸ”µ Blue: Data sources (external inputs)
- ğŸŸ¢ Green: Processing steps (internal computation)
- ğŸŸ¡ Yellow: LLM inference (neural network)
- ğŸ”´ Red: Output (final deliverable)

**Arrow Labels:**
- Weather API â†’ weather.csv: "5yr hourly â†’ weekly aggregation"
- EIA CSV â†’ household.csv: "Regional MW â†’ per-household kW"
- 3 CSVs â†’ Feature Engineering: "~45K data points â†’ 75 features"
- Knowledge.txt â†’ RAG: "158 lines â†’ 5 passages (TF-IDF cosine)"
- Features + RAG â†’ Prompt: "~6.5K chars â†’ 8K char structured prompt"
- Prompt â†’ LLM: "~2K tokens input â†’ 4K tokens max output"
- LLM â†’ Output: "Structured recommendation with sections"
